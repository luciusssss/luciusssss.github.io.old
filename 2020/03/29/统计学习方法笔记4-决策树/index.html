<!DOCTYPE html><html lang="zh-Hans"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Per aspera ad astra."><title>统计学习方法笔记4 决策树 | Blog - Lucius</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-174277081-1','auto');ga('send','pageview');
</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">统计学习方法笔记4 决策树</h1><a id="logo" href="/.">Blog - Lucius</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">统计学习方法笔记4 决策树</h1><div class="post-meta">2020-03-29<span> | </span><span class="category"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><a class="disqus-comment-count" data-disqus-identifier="2020/03/29/统计学习方法笔记4-决策树/" href="/2020/03/29/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B04-%E5%86%B3%E7%AD%96%E6%A0%91/#disqus_thread"></a><div class="post-content"><p>分类决策树由节点和有向边组成，内部节点表示一种特征或属性，叶节点表示分类。决策时学习主要有三个步骤：特征选择、决策树生成和决策树修建。</p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><p>决策树本质是从训练数据中归纳出一组分类规则。我们需要一个与训练数据矛盾较小的决策树，同时具有较好的泛化能力。</p>
<h1 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h1><p>如果特征过多，则需要对特征进行选择，只留下对于训练数据有足够分类能力的数据。如果用一个特征分类与随即分类的结果差别不大，那么这个特征是没有分类能力的。通常特征选择的准则是信息增益或信息增益比。</p>
<h2 id="熵"><a href="#熵" class="headerlink" title="熵"></a>熵</h2><p>首先给出熵的定义。熵是表示随机变量不确定性的度量。对于一个取有限个值得随机变量，概率分布为<br>$$<br>P(X = x_i) = p_i,\ i = 1, \dots, n<br>$$<br>随机变量$X$得熵为<br>$$<br>H(X) = H(p) = -\sum_{i = 1}^{n} p_i \log p_i<br>$$<br>随机变量$X$给定的条件下随机变量$Y$的条件熵为<br>$$<br>H(Y\mid X) = \sum_{i = 1}^{n } p_i H(Y | X = x_i)<br>$$<br>当熵和条件熵由数据估计得到时，分别称为经验熵和经验条件熵。</p>
<h2 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h2><p>信息增益表示知道特征$X$的信息而使类$Y$的信息不确定性减少的程度。</p>
<p>特征A对数据集D的信息增益$g(D,A)$定义为<br>$$<br>g(D, S) = H(D) - H(D\mid A)<br>$$<br>$|C_k|$为$D$中分类为$C_k$的样本数，根据特征$A$可以将$D$分成$D_1, \dots, D_n$，则<br>$$<br>H(D) = -\sum_{k = 1}^{K}\frac{|C_k|}{|D|}\log \frac{|C_k|}{|D|}<br>$$</p>
<p>$$<br>H(D|A) = \sum_{i=1}^{n}\frac{|D_i|}{|D|}H(D_i) = - \sum_{i=1}^{n}\frac{|D_i|}{|D|} \sum_{k=1}^{K}\frac{|D_{ik}|}{|D_i|} \log \frac{|D_{ik}|}{|D_i|}<br>$$</p>
<h2 id="信息增益比"><a href="#信息增益比" class="headerlink" title="信息增益比"></a>信息增益比</h2><p>以信息增益作为划分依据时，存在偏向于选择取值较多的特征的问题，可以使用信息增益比及逆行矫正。</p>
<p>特征$A$对于训练数据集$D$的信息增益比为信息增益于$D$关于$A$的值的熵<br>$$<br>g_{R}(D, A) = \frac{g(D, A)}{H_{A}(D)}<br>$$<br>其中$H_{A}(D) = -\sum_{i=1}^{n}\frac{|D_i|}{|D|}\log \frac{|D_i|}{|D|}$。</p>
<h1 id="决策树生成"><a href="#决策树生成" class="headerlink" title="决策树生成"></a>决策树生成</h1><h2 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a>ID3算法</h2><ol>
<li>若$D$总所有实例都属于$C_k$或特征集$A$为空，则设为叶子节点。</li>
<li>否则，选择$A$中信息增益最大的特征$A_g$。如果$A_g$信息增益小于阈值，则设为叶子节点。</li>
<li>否则，对$A_g$每个可能的取值，划分成非空子集当作子节点，从$A$删除该特征后对子节点递归调用。</li>
</ol>
<h2 id="C4-5算法"><a href="#C4-5算法" class="headerlink" title="C4.5算法"></a>C4.5算法</h2><p>把ID3算法中的信息增益改进成信息增益比。</p>
<h1 id="决策树剪枝"><a href="#决策树剪枝" class="headerlink" title="决策树剪枝"></a>决策树剪枝</h1><p>设树$T$叶子节点个数为$|T|$，叶节点$t$有$N_t$个样本点，其中类为$k$的样本点个数为$N_{tk}$，叶节点$t$的经验熵为$H_t(T)$，则可以定义以下损失函数<br>$$<br>C_{\alpha}(T) = \sum_{t=1}^{|T|}N_t H_t(T) + \alpha|T|<br>$$<br>右边第一项记为<br>$$<br>C(T) = -\sum_{t=1}^{|T|}N_t\sum_{k=1}^{K}\frac{N_{tk}}{N_t} \log \frac{N_{tk}}{N_t} = -\sum_{t=1}^{|T|}\sum_{k=1}^{K}N_{tk} \log \frac{N_{tk}}{N_t}<br>$$<br>则<br>$$<br>C_{\alpha}(T) = C(T) + \alpha |T|<br>$$<br>设一组叶节点回缩到父节点后整个树的损失减小，则进行剪枝，即将父节点变成新的叶节点。</p>
<h1 id="CART算法"><a href="#CART算法" class="headerlink" title="CART算法"></a>CART算法</h1><p>CART算法既可以用于分类也可用于分类，它每个内部节点进行对给定条件的是否判断，从而建立一颗二叉树。算法由生成和剪枝两部分组成。</p>
<h2 id="回归树生成"><a href="#回归树生成" class="headerlink" title="回归树生成"></a>回归树生成</h2><p>假设将输入空间分成$M$个单元，单元$R_m$上由固定输出值$c_m$，则回归树模型可以表示为<br>$$<br>f(x) = \sum_{m=1}^{M} c_{m} \mathrm{I}(x \in R_m)<br>$$<br>用平方误差最小的准则求解每个单元上的最优输出值得到<br>$$<br>\hat{c_m} = \mathrm{ave}(y_i\mid x_i \in R_m)<br>$$<br>选择第$j$个变量$x^{(j)}$的值$s$为切分点，可以得到两个区域<br>$$<br>R_1(j, s) = {x\mid x^{(j)} \leq s },\  R_2(j, s) = {x\mid x^{(j)} &gt; s }<br>$$<br>在生成算法中，每步选取最优的切分变量$j$和切分点$s$，即求解<br>$$<br>\min_{j, s} ( \min_{c_1}\sum_{x_i \in R_1(j,s)} (y_i - c_1)^2 + \min_{c_2}\sum_{x_i \in R_2(j,s)} (y_i - c_2)^2 )<br>$$<br>对于选定的$(j, s)$对划分区域并决定对应的输出值。</p>
<h2 id="分类树生成"><a href="#分类树生成" class="headerlink" title="分类树生成"></a>分类树生成</h2><p>先定义基尼指数：分类问题中，$K$个类，样本点属于第$k$类的概率为$p_k$，则<br>$$<br>\mathrm{Gini}(p) = \sum_{k=1}^{K} p_k (1-p_k) = 1 - \sum_{k=1}^{K} p_k^2<br>$$<br>如果样本集合$D$根据特征$A$是否取某一可能值$a$被分为$D_1$和$D_2$，则在特征$A$的条件下，集合$D$的基尼指数为<br>$$<br>\textrm{Gini(D, A)} = \frac{|D_1|}{|D|}\mathrm{Gini}(D_1) + \frac{|D_2|}{|D|}\mathrm{Gini}(D_2)<br>$$<br>每次确定内部节点时，选择基尼指数最小的（特征，切分点）进行划分。</p>
<h2 id="CART剪枝"><a href="#CART剪枝" class="headerlink" title="CART剪枝"></a>CART剪枝</h2><ol>
<li><p>设$k = 0, T = T_0$。</p>
</li>
<li><p>令$\alpha = + \infty$。</p>
</li>
<li><p>自下而上地对各内部节点$t$计算$C(T_t), |T_t|$和<br>$$<br>g(t) = \frac{C(t) - C(T_t)}{|T_t| - 1}<br>$$</p>
<p>$$<br>\alpha = \min(\alpha, g(t))<br>$$</p>
<p>$T_t$表示以$t$为根节点的子树。</p>
</li>
<li><p>对$g(t) = \alpha$的内部节点$t$进行剪枝，得到树$T$。（因为当$\alpha$大于$g(t)$时，剪枝会使损失函数减少，随着$\alpha$增加，总有某棵子树改剪。cart树怎么进行剪枝？ - FuriousFatty的回答 - 知乎 <a href="https://www.zhihu.com/question/22697086/answer/134841101" target="_blank" rel="noopener">https://www.zhihu.com/question/22697086/answer/134841101</a>  ）</p>
</li>
<li><p>令$k = k + 1, \alpha_k = \alpha, T_k = T$。</p>
</li>
<li><p>如果$T_k$不是由一个根节点和两个叶节点组成的树，则回到步骤2；否则令$T_k = T_n$。</p>
</li>
<li><p>使用交叉验证从$T_1, T_2, \dots, T_n$中选出最优子树$T_\alpha$。</p>
</li>
</ol>
</div><div class="tags"><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><i class="fa fa-tag"></i>机器学习</a><a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"><i class="fa fa-tag"></i>统计学习方法</a></div><div class="post-nav"><a class="pre" href="/2020/04/12/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B05-SVM/">统计学习方法笔记5 SVM</a><a class="next" href="/2020/03/28/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B03-k%E8%BF%91%E9%82%BB/">统计学习方法笔记3 k近邻</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论（请确保 Disqus 可以正常加载）</button></div><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'http://luciusssss.github.io/2020/03/29/统计学习方法笔记4-决策树/';
    this.page.identifier = '2020/03/29/统计学习方法笔记4-决策树/';
    this.page.title = '统计学习方法笔记4 决策树';
  };</script><script type="text/javascript" id="disqus-lazy-load-script">$.ajax({
url: 'https://disqus.com/next/config.json',
timeout: 2500,
type: 'GET',
success: function(){
  var d = document;
  var s = d.createElement('script');
  s.src = '//lucius.disqus.com/embed.js';
  s.setAttribute('data-timestamp', + new Date());
  (d.head || d.body).appendChild(s);
  $('.disqus_click_btn').css('display', 'none');
},
error: function() {
  $('.disqus_click_btn').css('display', 'block');
}
});</script><script type="text/javascript" id="disqus-click-load">$('.btn_click_load').click(() => {  //click to load comments
    (() => { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//lucius.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
    $('.disqus_click_btn').css('display','none');
});</script><script type="text/javascript" id="disqus-count-script">$(function() {
     var xhr = new XMLHttpRequest();
     xhr.open('GET', '//disqus.com/next/config.json', true);
     xhr.timeout = 2500;
     xhr.onreadystatechange = function () {
       if (xhr.readyState === 4 && xhr.status === 200) {
         $('.post-meta .post-comments-count').show();
         var s = document.createElement('script');
         s.id = 'dsq-count-scr';
         s.src = 'https://lucius.disqus.com/count.js';
         s.async = true;
         (document.head || document.body).appendChild(s);
       }
     };
     xhr.ontimeout = function () { xhr.abort(); };
     xhr.send(null);
   });
</script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://luciusssss.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E8%AF%91/">编译</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87/">论文</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 15px;">数据结构</a> <a href="/tags/%E4%BA%8C%E5%88%86/" style="font-size: 15px;">二分</a> <a href="/tags/%E9%98%9F%E5%88%97/" style="font-size: 15px;">队列</a> <a href="/tags/%E6%A0%88/" style="font-size: 15px;">栈</a> <a href="/tags/%E8%AE%BA%E6%96%87/" style="font-size: 15px;">论文</a> <a href="/tags/QA/" style="font-size: 15px;">QA</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 15px;">算法</a> <a href="/tags/%E6%A0%91/" style="font-size: 15px;">树</a> <a href="/tags/%E8%B4%AA%E5%BF%83/" style="font-size: 15px;">贪心</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">机器学习</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 15px;">统计学习方法</a> <a href="/tags/%E7%BC%96%E8%AF%91/" style="font-size: 15px;">编译</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/08/03/Stanford-Compilers-%E7%AC%94%E8%AE%B0/">Stanford Compilers 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/12/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B05-SVM/">统计学习方法笔记5 SVM</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/29/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B04-%E5%86%B3%E7%AD%96%E6%A0%91/">统计学习方法笔记4 决策树</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/28/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B03-k%E8%BF%91%E9%82%BB/">统计学习方法笔记3 k近邻</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B02-%E6%84%9F%E7%9F%A5%E6%9C%BA/">统计学习方法笔记2 感知机</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B01-%E6%A6%82%E8%AE%BA/">统计学习方法笔记1 概论</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/20/LeetCode%E4%BA%8C%E5%88%86-%E9%98%9F%E5%88%97-%E6%A0%88%E4%B8%93%E9%A2%98/">LeetCode二分/队列/栈专题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/LeetCode%E6%A0%91%E4%B8%93%E9%A2%98/">LeetCode树专题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/06/LeetCode%E8%B4%AA%E5%BF%83%E4%B8%93%E9%A2%98/">LeetCode贪心专题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/28/LeetCode%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0-2/">LeetCode刷题笔记 2</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> Recent Comments</i></div><script type="text/javascript" src="//lucius.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://github.com/luciusssss" title="My Github" target="_blank">My Github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">Blog - Lucius.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js" successtext="Copy Successed!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --></body></html>