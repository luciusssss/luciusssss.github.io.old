<!DOCTYPE html><html lang="zh-Hans"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Per aspera ad astra."><title>统计学习方法笔记2 感知机 | Blog - Lucius</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-174277081-1','auto');ga('send','pageview');
</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">统计学习方法笔记2 感知机</h1><a id="logo" href="/.">Blog - Lucius</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">统计学习方法笔记2 感知机</h1><div class="post-meta">2020-03-27<span> | </span><span class="category"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><a class="disqus-comment-count" data-disqus-identifier="2020/03/27/统计学习方法笔记2-感知机/" href="/2020/03/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B02-%E6%84%9F%E7%9F%A5%E6%9C%BA/#disqus_thread"></a><div class="post-content"><p>从模型-&gt;策略-&gt;算法的思路来描述感知机！</p>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><h1 id="感知机模型"><a href="#感知机模型" class="headerlink" title="感知机模型"></a>感知机模型</h1><p>输入空间为$\mathcal{X} \subseteq \mathbb{R}^{n}$，输出空间为$\mathcal{Y} = {+1, -1}$，从输入空间到输出空间的函数$f(x) = \mathrm{sign}(w\cdot x + b)$称为感知机。$w\cdot x + b = 0$对应特征空间$ \mathbb{R}^{n}$内的一个超平面，将特征空间分成两部分。</p>
<a id="more"></a>

<h1 id="感知机学习策略"><a href="#感知机学习策略" class="headerlink" title="感知机学习策略"></a>感知机学习策略</h1><p>假设数据集是线性可分的，感知机的学习目标是是找到一个能将正负例完全区分开的超平面。</p>
<p>对于损失函数，一个naive的想法是误分类点的总数，但是这个函数对于模型参数$w,b$不可导，不易优化。另一个想法是误分类点到超平面距离之和$\sum_{x_i\in M}\frac{1}{|w|}|w\cdot x_i + b|$。因为对于误分类点有$y(w\cdot x + b) &lt; 0$，所以可以把绝对值拆掉，同时省掉$w$的$L_2$范数，得到最终的损失函数为<br>$$<br>L(w, b) = - \sum_{x_i \in M} y_i(w\cdot x_i + b)<br>$$<br>其中$M$为误分类的点集。误分类点越少，误分类点离超平面越近，损失函数值越小。</p>
<h1 id="感知机学习算法"><a href="#感知机学习算法" class="headerlink" title="感知机学习算法"></a>感知机学习算法</h1><h2 id="原始形式"><a href="#原始形式" class="headerlink" title="原始形式"></a>原始形式</h2><p>感知机算法是误分类驱动的，可以采用随机梯度下降进行参数更新。</p>
<p>假设误分类点集$M$是固定的，损失函数的梯度为<br>$$<br>\nabla_{w} L(w, b) = -\sum_{x_i \in M} y_i\cdot x_i<br>$$</p>
<p>$$<br>\nabla_b L(w, b) = -\sum_{x_i \in M} y_i<br>$$</p>
<p>随机选取一个误分类点对参数进行更新<br>$$<br>w \gets w + \eta y_ix_i<br>$$</p>
<p>$$<br>b \gets b + \eta y_i<br>$$</p>
<p>其中$\eta$为学习率。</p>
<p>直观上看，当一个实例点被误分类，就调增超平面朝该误分类点的一侧移动。</p>
<p>对于参数的不同初值和不同误分类点的选取可能会得出不同的解。</p>
<h2 id="收敛性"><a href="#收敛性" class="headerlink" title="收敛性"></a>收敛性</h2><p>（以下分析把参数$b$合并到$w$中，同时特征向量里添加一个1）</p>
<p>由于训练集是线性可分的，所以存在一个超平面$w_{opt}$满足$|w_{opt}| = 1$能将数据集完全分开。取$\gamma = \min_{i} y_i(w_{opt}\cdot x_i)$，则有对所有$i = 1, \dots, N$，有$y_i(w_{opt}\cdot x_i) \geq \gamma$。</p>
<p>令$R = \max_{i}|x_i|$，$w_0 = 0$。若$(x_i, y_i)$为第$k$个被误分类的数据，梯度更新得到$w_k = w_{k-1} + \eta y_i x_i$。</p>
<p>一方面，$w_k \cdot w_{opt} = (w_{k-1} + \eta y_i x_i)w_{opt} \geq w_{k-1}w_{opt} + \eta \gamma \geq \dots \geq k\eta \gamma$。</p>
<p> 另一方面有，$|w_{k}|^{2} = |w_{k-1}|^{2} + 2\eta y_i w_{k-1}\cdot x_i + \eta^2|x_i|^2 \leq |w_{k-1}|^{2} + \eta^2 R^2 \leq \dots \leq k\eta^2R^2$ 。</p>
<p>所以有<br>$$<br>k\eta \gamma\leq w_k \cdot w_{opt} \leq |w_{k}||w_{opt}| \leq \sqrt{k} \eta R<br>$$<br>从而得到<br>$$<br>k \leq (\frac{R}{\gamma})^2<br>$$<br>感知机算法的原始形式迭代是收敛的！</p>
<h2 id="对偶形式"><a href="#对偶形式" class="headerlink" title="对偶形式"></a>对偶形式</h2><p>基本想法是将$w,b$表示为$x_i, y_i$线性组合的形式（这也是SVM的基本思想）。</p>
<p>不妨将$w,b$初始设为0。对于误分类点$(x_i, y_i)$通过梯度更新$n_i$次，相当于对$w$加了$n_i$次$\eta y_i x_i$，对$b$加了$n_i$次$\eta y_i$。l令$\alpha_i = n_i\eta$这样最后学到的$w,b$可以表示成<br>$$<br>w = \sum_{i=1}^{N} \alpha_i y_i x_i<br>$$</p>
<p>$$<br>b = \sum_{i=0}^{N}\alpha_i y_i<br>$$</p>
<p>当$\eta = 1$时，$\alpha_i$相当于这个实例点因为误分类而更新的次数。</p>
<p>在对偶形式的算法中，如果$y_i(\sum_{j=1}^{N} \alpha_j y_j x_j \cdot x_i + b) \leq 0$，则进行如下更新<br>$$<br>a_i \gets a_i + \eta<br>$$</p>
<p>$$<br>b \gets b + \eta y_i<br>$$</p>
<p>训练实例仅以内积出现，所以可以预先计算出所有内积储存为矩阵，也就是Gram矩阵<br>$$<br>\mathbf{G} = [x_i \cdot x_j]_{N\times N}<br>$$</p>
<h1 id="习题"><a href="#习题" class="headerlink" title="习题"></a>习题</h1><ol>
<li><p>验证感知机为什么不能表示异或。</p>
<p>对于两个元素的异或，有四种情况$(1, 1) \to 0$, $(1, 0) \to 1$，$(0,1)\to 1$，$(0, 0) \to 0$。而这四个点放到平面上，不是线性可分的。</p>
</li>
<li><p>构建从数据集求解感知机模型的例子。</p>
<p>例2.1 Python实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">InnerProduct</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    res = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i, j <span class="keyword">in</span> zip(a, b):</span><br><span class="line">        res += i*j</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line">X = [[<span class="number">3</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">1</span>]]</span><br><span class="line">Y = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">iteration = <span class="number">10</span></span><br><span class="line">eta = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">w = [<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">b = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(iteration):</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(X, Y):</span><br><span class="line">        <span class="keyword">if</span> y * (InnerProduct(w, x) + b) &lt;= <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> range(len(w)):</span><br><span class="line">                w[k] += eta * y * x[k]</span><br><span class="line">            b += eta * y</span><br><span class="line"></span><br><span class="line">all_seperated = <span class="literal">True</span></span><br><span class="line"><span class="keyword">for</span> x, y <span class="keyword">in</span> zip(X, Y):</span><br><span class="line">    <span class="keyword">if</span> y * (InnerProduct(w, x) + b) &lt;= <span class="number">0</span>:</span><br><span class="line">        all_seperated = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> all_seperated:</span><br><span class="line">    print(<span class="string">'Hyperplane found!'</span>)</span><br><span class="line">    print(<span class="string">'w:'</span>, w, <span class="string">"b:"</span>, b)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">'Hyperplane not found...'</span>)</span><br></pre></td></tr></table></figure>



</li>
</ol>
<ol start="3">
<li><p>证明：样本集线性可分的充要条件是正实例点集构成的凸壳和负实例点集构成的凸壳互不相交。定义$S = {x_1, \dots, x_k}$的凸壳$\mathrm{conv}(S) = {x = \sum_{i=1}^{k}\lambda_ix_i \mid \sum_{i =1}^{k}\lambda_i = 1, \lambda_i \geq 0, i = 1, \dots, k}$</p>
<p>设正例有$x_{p_1},  \dots, x_{p_k}$，负例有 $x_{q_1},  \dots, x_{q_m}$</p>
<p>($\Rightarrow$)</p>
<p>反证：假设正负点集的凸壳相交，即存在点$x_t$满足$x_t = \sum_{i = p_1}^{p_k} \lambda_i x_i = \sum_{j = q_1}^{q_m} \lambda_j x_j$。因为样本集线性可分，所以存在$w, b$使得对所有正例有$w\cdot x + b &gt; 0$，所有负例有$w \cdot x + b &lt; 0$。从而有$\sum_{i = p_1}^{p_k}\lambda_i (w \cdot x_i + b) = w \cdot x_t + b &gt; 0$。同理有$w\cdot x_t + b &lt; 0$ ，矛盾！</p>
<p>($\Leftarrow$)</p>
<p>直观上，凸壳不交则凸壳线性可分，从而正负点集线性可分。严谨的证明见<a href="https://blog.csdn.net/y954877035/article/details/52210734" target="_blank" rel="noopener">https://blog.csdn.net/y954877035/article/details/52210734</a></p>
</li>
</ol>
</div><div class="tags"><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><i class="fa fa-tag"></i>机器学习</a><a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"><i class="fa fa-tag"></i>统计学习方法</a></div><div class="post-nav"><a class="pre" href="/2020/03/28/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B03-k%E8%BF%91%E9%82%BB/">统计学习方法笔记3 k近邻</a><a class="next" href="/2020/03/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B01-%E6%A6%82%E8%AE%BA/">统计学习方法笔记1 概论</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论（请确保 Disqus 可以正常加载）</button></div><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'http://luciusssss.github.io/2020/03/27/统计学习方法笔记2-感知机/';
    this.page.identifier = '2020/03/27/统计学习方法笔记2-感知机/';
    this.page.title = '统计学习方法笔记2 感知机';
  };</script><script type="text/javascript" id="disqus-lazy-load-script">$.ajax({
url: 'https://disqus.com/next/config.json',
timeout: 2500,
type: 'GET',
success: function(){
  var d = document;
  var s = d.createElement('script');
  s.src = '//lucius.disqus.com/embed.js';
  s.setAttribute('data-timestamp', + new Date());
  (d.head || d.body).appendChild(s);
  $('.disqus_click_btn').css('display', 'none');
},
error: function() {
  $('.disqus_click_btn').css('display', 'block');
}
});</script><script type="text/javascript" id="disqus-click-load">$('.btn_click_load').click(() => {  //click to load comments
    (() => { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//lucius.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
    $('.disqus_click_btn').css('display','none');
});</script><script type="text/javascript" id="disqus-count-script">$(function() {
     var xhr = new XMLHttpRequest();
     xhr.open('GET', '//disqus.com/next/config.json', true);
     xhr.timeout = 2500;
     xhr.onreadystatechange = function () {
       if (xhr.readyState === 4 && xhr.status === 200) {
         $('.post-meta .post-comments-count').show();
         var s = document.createElement('script');
         s.id = 'dsq-count-scr';
         s.src = 'https://lucius.disqus.com/count.js';
         s.async = true;
         (document.head || document.body).appendChild(s);
       }
     };
     xhr.ontimeout = function () { xhr.abort(); };
     xhr.send(null);
   });
</script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://luciusssss.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E8%AF%91/">编译</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87/">论文</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 15px;">数据结构</a> <a href="/tags/%E4%BA%8C%E5%88%86/" style="font-size: 15px;">二分</a> <a href="/tags/%E9%98%9F%E5%88%97/" style="font-size: 15px;">队列</a> <a href="/tags/%E6%A0%88/" style="font-size: 15px;">栈</a> <a href="/tags/%E8%AE%BA%E6%96%87/" style="font-size: 15px;">论文</a> <a href="/tags/QA/" style="font-size: 15px;">QA</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 15px;">算法</a> <a href="/tags/%E6%A0%91/" style="font-size: 15px;">树</a> <a href="/tags/%E8%B4%AA%E5%BF%83/" style="font-size: 15px;">贪心</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">机器学习</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 15px;">统计学习方法</a> <a href="/tags/%E7%BC%96%E8%AF%91/" style="font-size: 15px;">编译</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/08/03/Stanford-Compilers-%E7%AC%94%E8%AE%B0/">Stanford Compilers 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/12/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B05-SVM/">统计学习方法笔记5 SVM</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/29/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B04-%E5%86%B3%E7%AD%96%E6%A0%91/">统计学习方法笔记4 决策树</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/28/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B03-k%E8%BF%91%E9%82%BB/">统计学习方法笔记3 k近邻</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B02-%E6%84%9F%E7%9F%A5%E6%9C%BA/">统计学习方法笔记2 感知机</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B01-%E6%A6%82%E8%AE%BA/">统计学习方法笔记1 概论</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/20/LeetCode%E4%BA%8C%E5%88%86-%E9%98%9F%E5%88%97-%E6%A0%88%E4%B8%93%E9%A2%98/">LeetCode二分/队列/栈专题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/LeetCode%E6%A0%91%E4%B8%93%E9%A2%98/">LeetCode树专题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/06/LeetCode%E8%B4%AA%E5%BF%83%E4%B8%93%E9%A2%98/">LeetCode贪心专题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/28/LeetCode%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0-2/">LeetCode刷题笔记 2</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> Recent Comments</i></div><script type="text/javascript" src="//lucius.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://github.com/luciusssss" title="My Github" target="_blank">My Github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">Blog - Lucius.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js" successtext="Copy Successed!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --></body></html>