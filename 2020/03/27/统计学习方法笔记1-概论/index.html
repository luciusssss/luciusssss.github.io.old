<!DOCTYPE html><html lang="zh-Hans"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Per aspera ad astra."><title>统计学习方法笔记1 概论 | Blog - Lucius</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-174277081-1','auto');ga('send','pageview');
</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">统计学习方法笔记1 概论</h1><a id="logo" href="/.">Blog - Lucius</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">统计学习方法笔记1 概论</h1><div class="post-meta">2020-03-27<span> | </span><span class="category"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><a class="disqus-comment-count" data-disqus-identifier="2020/03/27/统计学习方法笔记1-概论/" href="/2020/03/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B01-%E6%A6%82%E8%AE%BA/#disqus_thread"></a><div class="post-content"><h1 id="统计学习的分类"><a href="#统计学习的分类" class="headerlink" title="统计学习的分类"></a>统计学习的分类</h1><h2 id="基本分类"><a href="#基本分类" class="headerlink" title="基本分类"></a>基本分类</h2><h3 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h3><ul>
<!-- hexo-inject:begin --><!-- hexo-inject:end --><li>本质是学习输入到输出映射的统计规律。</li>
<li>假设输入与输出的随机变量$X$和$Y$遵循联合概率分布$P(X, Y)$。</li>
<li>模型可以表示$P(y\mid x)$或$y = f(x)$。</li>
</ul>
<h3 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h3><ul>
<li>本质是学习数据中的统计规律或潜在结构。</li>
<li>$Z$是隐式结构空间。模型可以表示成$z = g(x)$，$P(z\mid x)$或$P(x\mid z)$。前两者用于聚类和降维，最后一个用于概率估计。</li>
</ul>
<h3 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h3><ul>
<li>目标是长期累积的奖励最大化</li>
</ul>
<h3 id="半监督学习与主动学习"><a href="#半监督学习与主动学习" class="headerlink" title="半监督学习与主动学习"></a>半监督学习与主动学习</h3><ul>
<li><p>半监督拥有少量标注数据，大量未标注数据。</p>
</li>
<li><p>主动学习中机器会主动给实例让教师标注。</p>
</li>
<li><p>这两者更接近监督学习。</p>
</li>
</ul>
<a id="more"></a>

<h2 id="按模型分类"><a href="#按模型分类" class="headerlink" title="按模型分类"></a>按模型分类</h2><h3 id="概率模型与非概率模型"><a href="#概率模型与非概率模型" class="headerlink" title="概率模型与非概率模型"></a>概率模型与非概率模型</h3><ul>
<li>前者模型是条件概率分布的形式，后者模型是函数的形式，后者又叫确定性模型。</li>
<li>条件概率分布和函数可以转化：条件概率分布最大化后得到函数，函数归一化后得到条件分布。但这不是概率模型与非概率模型的区别。概率模型一定可以表示为联合概率分布的形式，而非概率模型不一定。</li>
</ul>
<h3 id="线性模型和非线性模型"><a href="#线性模型和非线性模型" class="headerlink" title="线性模型和非线性模型"></a>线性模型和非线性模型</h3><ul>
<li>对于非概率模型，如果$y=f(x)$或$z =g(x)$是线性函数，则称为线性模型，否则为非线性模型。</li>
</ul>
<h3 id="参数化模型和非参数化模型"><a href="#参数化模型和非参数化模型" class="headerlink" title="参数化模型和非参数化模型"></a>参数化模型和非参数化模型</h3><ul>
<li>前者假设模型参数的维度固定，模型可以由有限维参数完全刻画；后者假设模型参数维度不固定或者无穷尽广大，随着训练数据量的增加而增大。</li>
</ul>
<h3 id="生成模型和判别模型"><a href="#生成模型和判别模型" class="headerlink" title="生成模型和判别模型"></a>生成模型和判别模型</h3><ul>
<li>监督学习中，生成模型先由数据学习联合概率分布$P(X, Y)$，然后求出条件概率分布$P(Y\mid X)$。而判别模型由数据直接学习决策函数$f(X)$或条件概率分布$P(Y\mid X)$。</li>
<li>生成方法：学习收敛速度快；存在隐变量时也适用。</li>
<li>判别方法：学习准确率高；可以对数据进行各种程度的抽象、定义特征并使用特征，因此可以简化学习问题。</li>
</ul>
<h1 id="统计学习方法三要素"><a href="#统计学习方法三要素" class="headerlink" title="统计学习方法三要素"></a>统计学习方法三要素</h1><p>方法 = 模型 + 策略 + 算法</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>模型就是所要学习的条件概率分布或决策函数。模型的假设空间$\mathcal{F}$包含所有可能的条件概率分布或决策函数。</p>
<h2 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h2><p>策略就是按照怎样的准则学习或选择最优模型。</p>
<p>使用损失函数$L(Y, f(X))$来度量输出预测$f(X)$和真实值$Y$的不一致程度。</p>
<p>风险函数/期望损失：<br>$$<br>R_{exp}(f) = E_P[L(Y, f(X))] = \int_{\mathcal{X}\times\mathcal{Y}}L(y, f(x))P(x, y)\mathrm{d}x\mathrm{d}y<br>$$<br>在给定训练数据集上的经验风险：<br>$$<br>R_{emp}(f) = \frac{1}{N}\sum_{i=1}^{N}L(y_i, f(x_i))<br>$$<br>当样本容量趋近于无穷时，经验风险也就趋近于期望风险，于是可以用经验风险估计期望风险。但是现实中训练样本有限，这样估计效果并不好，所以要对经验风险进行矫正。</p>
<p>从上可以得到两个策略</p>
<ul>
<li><p>经验风险最小化（ERM）：认为最优化模型是经验风险最小的。</p>
</li>
<li><p>结构风险最小化（SRM）：为了避免过拟合，加入模型复杂度$J(f)$的惩罚，得到结构风险<br>$$<br>R_{srm}(f) = \frac{1}{N}\sum_{i=1}^{N}L(y_i, f(x_i)) + \lambda J(f)<br>$$</p>
</li>
</ul>
<h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>算法就是学习模型的具体计算方法。</p>
<h1 id="习题"><a href="#习题" class="headerlink" title="习题"></a>习题</h1><ol>
<li><p>说明伯努利模型的极大似然估计和贝叶斯估计中的统计学习方法三要素。</p>
<p>模型：都是在取值为0和1的随机变量上的概率分布。</p>
<p>策略&amp;算法：极大似然估计：<br>$$<br>\frac{\partial\ln L(p)}{\partial p} = \frac {\partial\ln \dbinom{n}{k}p^{k}(1-p)^{n-k}}{\partial p} = kp^{k-1}(1-p)^{n-k} - (n-k)p^k(1-p)^{n-k-1} = 0<br>$$<br>得到$p = \frac{k}{n}$。</p>
<p>贝叶斯估计：</p>
<p>先验地认为$p$在$[0, 1]$均匀分布，所以先验概率密度函数$f(p) = 1$。<br>$$<br>f(p \mid D) = \frac{f(D\mid \theta)f(\theta)}{f(D)}<br>$$<br>要使后验概率最大，也就要使$f(D\mid \theta)$最大。（此时贝叶斯估计和极大似然估计是可以联系起来的。）</p>
</li>
<li><p>通过经验风险最小化推导极大似然估计。证明模型是条件概率分布时，当损失函数是对数损失函数时，经验风险最小化等价于极大似然估计。</p>
<p>给定数据集${(x_1, y_1), \dots, (x_N, y_N)}$，各个数据独立同分布。模型$P(Y\mid X)$关于数据集的经验风险为<br>$$<br>R_{emp}(f) = \frac{1}{N} \sum_{i=1}^{N}L(y_i,P(yi\mid X)) = -\frac{1}{N}\log P(y_i\mid x)<br>$$<br>经验风险最小化就是求解最优化问题<br>$$<br>\min_{P\in \mathcal{F}}-\frac{1}{N}\log P(y_i\mid x)<br>$$<br>而对于极大似然估计，对于模型参数$\theta$，似然函数为<br>$$<br>L(\theta) = \prod_{i=1}^{N}P(y_i\mid x_i)<br>$$<br>对其取对数为<br>$$<br>\log L(\theta) = \log \prod_{i=1}^{N}P(y_i\mid x_i) = \sum_{i=1}^{N}\log P(y_i\mid x_i)<br>$$<br>要进行极大似然，也就是要<br>$$<br>\max_{\theta} \sum_{i=1}^{N}\log P(y_i\mid x_i)<br>$$<br>可以看到，经验风险最小化等价于极大似然估计。</p>
</li>
</ol>
</div><div class="tags"><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><i class="fa fa-tag"></i>机器学习</a><a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"><i class="fa fa-tag"></i>统计学习方法</a></div><div class="post-nav"><a class="pre" href="/2020/03/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B02-%E6%84%9F%E7%9F%A5%E6%9C%BA/">统计学习方法笔记2 感知机</a><a class="next" href="/2020/02/20/LeetCode%E4%BA%8C%E5%88%86-%E9%98%9F%E5%88%97-%E6%A0%88%E4%B8%93%E9%A2%98/">LeetCode二分/队列/栈专题</a></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论（请确保 Disqus 可以正常加载）</button></div><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'http://luciusssss.github.io/2020/03/27/统计学习方法笔记1-概论/';
    this.page.identifier = '2020/03/27/统计学习方法笔记1-概论/';
    this.page.title = '统计学习方法笔记1 概论';
  };</script><script type="text/javascript" id="disqus-lazy-load-script">$.ajax({
url: 'https://disqus.com/next/config.json',
timeout: 2500,
type: 'GET',
success: function(){
  var d = document;
  var s = d.createElement('script');
  s.src = '//lucius.disqus.com/embed.js';
  s.setAttribute('data-timestamp', + new Date());
  (d.head || d.body).appendChild(s);
  $('.disqus_click_btn').css('display', 'none');
},
error: function() {
  $('.disqus_click_btn').css('display', 'block');
}
});</script><script type="text/javascript" id="disqus-click-load">$('.btn_click_load').click(() => {  //click to load comments
    (() => { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//lucius.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
    $('.disqus_click_btn').css('display','none');
});</script><script type="text/javascript" id="disqus-count-script">$(function() {
     var xhr = new XMLHttpRequest();
     xhr.open('GET', '//disqus.com/next/config.json', true);
     xhr.timeout = 2500;
     xhr.onreadystatechange = function () {
       if (xhr.readyState === 4 && xhr.status === 200) {
         $('.post-meta .post-comments-count').show();
         var s = document.createElement('script');
         s.id = 'dsq-count-scr';
         s.src = 'https://lucius.disqus.com/count.js';
         s.async = true;
         (document.head || document.body).appendChild(s);
       }
     };
     xhr.ontimeout = function () { xhr.abort(); };
     xhr.send(null);
   });
</script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://luciusssss.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E8%AF%91/">编译</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87/">论文</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/LeetCode/" style="font-size: 15px;">LeetCode</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 15px;">数据结构</a> <a href="/tags/%E4%BA%8C%E5%88%86/" style="font-size: 15px;">二分</a> <a href="/tags/%E9%98%9F%E5%88%97/" style="font-size: 15px;">队列</a> <a href="/tags/%E6%A0%88/" style="font-size: 15px;">栈</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 15px;">算法</a> <a href="/tags/%E8%AE%BA%E6%96%87/" style="font-size: 15px;">论文</a> <a href="/tags/QA/" style="font-size: 15px;">QA</a> <a href="/tags/%E7%BC%96%E8%AF%91/" style="font-size: 15px;">编译</a> <a href="/tags/%E6%A0%91/" style="font-size: 15px;">树</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">机器学习</a> <a href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" style="font-size: 15px;">统计学习方法</a> <a href="/tags/%E8%B4%AA%E5%BF%83/" style="font-size: 15px;">贪心</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/08/03/Stanford-Compilers-%E7%AC%94%E8%AE%B0/">Stanford Compilers 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/12/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B05-SVM/">统计学习方法笔记5 SVM</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/29/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B04-%E5%86%B3%E7%AD%96%E6%A0%91/">统计学习方法笔记4 决策树</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/28/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B03-k%E8%BF%91%E9%82%BB/">统计学习方法笔记3 k近邻</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B02-%E6%84%9F%E7%9F%A5%E6%9C%BA/">统计学习方法笔记2 感知机</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/03/27/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B01-%E6%A6%82%E8%AE%BA/">统计学习方法笔记1 概论</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/20/LeetCode%E4%BA%8C%E5%88%86-%E9%98%9F%E5%88%97-%E6%A0%88%E4%B8%93%E9%A2%98/">LeetCode二分/队列/栈专题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/LeetCode%E6%A0%91%E4%B8%93%E9%A2%98/">LeetCode树专题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/06/LeetCode%E8%B4%AA%E5%BF%83%E4%B8%93%E9%A2%98/">LeetCode贪心专题</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/28/LeetCode%E5%88%B7%E9%A2%98%E7%AC%94%E8%AE%B0-2/">LeetCode刷题笔记 2</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> Recent Comments</i></div><script type="text/javascript" src="//lucius.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://github.com/luciusssss" title="My Github" target="_blank">My Github</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">Blog - Lucius.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js" successtext="Copy Successed!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --></body></html>