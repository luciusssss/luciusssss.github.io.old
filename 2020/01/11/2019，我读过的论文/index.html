<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 2019ï¼Œæˆ‘è¯»è¿‡çš„è®ºæ–‡ Â· Blog - Lucius</title><meta name="description" content="2019ï¼Œæˆ‘è¯»è¿‡çš„è®ºæ–‡ - Lucius"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/css/prontera.css"><link rel="search" type="application/opensearchdescription+xml" href="http://luciusssss.github.io/atom.xml" title="Blog - Lucius"><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="Blog - Lucius" type="application/atom+xml">
</head><body><header class="feature-header"><nav class="component-nav"><ul><div class="logo-container"><a href="/"><h2 class="title">Blog - Lucius</h2></a></div><a href="/" target="_self" class="li component-nav-item"><p>INDEX</p></a><a href="/archives" target="_self" class="li component-nav-item"><p>ARCHIVES</p></a><a href="/about" target="_self" class="li component-nav-item"><p>ABOUT</p></a><ul class="shortcut-icons"><a href="https://github.com/luciusssss" target="_blank"><img src="/images/github.svg" class="icon"></a></ul></ul></nav></header><main class="container"><div id="post-container"><div class="post"><article class="post-block"><h1 class="post-title">2019ï¼Œæˆ‘è¯»è¿‡çš„è®ºæ–‡</h1><div class="post-info">Jan 11, 2020</div><div class="post-content"><p>å»å¹´å¼€å§‹è®¤çœŸè¯»è®ºæ–‡è¿˜æ˜¯ä»7æœˆå¼€å§‹ï¼Œä¸»è¦è¯»äº†å¾ˆå¤šQuestion Answeringçš„è®ºæ–‡ï¼Œå…¶ä¸­åˆä»¥Machine Reading Comprehensionä¸ºä¸»ï¼Œå¤§æ¦‚äº†è§£äº†QAè¿™ä¸ªé¢†åŸŸåœ¨åšäº›ä»€ä¹ˆã€‚<br>è¿™é‡Œæˆ‘æŠŠå»å¹´è¯»è¿‡çš„è®ºæ–‡ç®€å•åˆ—ä¸€ä¸‹ã€‚å…¶ä¸­æˆ‘è§‰å¾—å€¼å¾—ä¸€è¯»çš„è®ºæ–‡æˆ‘ä¼šæ‰“ä¸ŠğŸ˜»ã€‚<br>é˜…è¯»è¿‡ç¨‹ä¸­å°¤å…¶æ„Ÿè°¢LAI Yuxuanå¸ˆå…„çš„æŒ‡å¯¼ï¼</p>
<a id="more"></a>

<h2 id="Survey"><a href="#Survey" class="headerlink" title="Survey"></a>Survey</h2><ul>
<li><p>NEURAL READING COMPREHENSION AND BEYOND ğŸ˜»<br><em>Chen Danqi</em><br>é™ˆä¸¹ç¦çš„åšå£«æ¯•ä¸šè®ºæ–‡ï¼Œä¸€ç¯‡å¯¹MRCæ¯”è¾ƒå…¨é¢ä¸”æ˜“æ‡‚çš„ç»¼è¿°ã€‚</p>
</li>
<li><p>Neural Machine Reading Comprehension: Methods and Trends<br><em>Shanshan Liu, Xin Zhang, Sheng Zhang, Hui Wang, Weiming Zhang</em><br>å›½é˜²ç§‘å¤§çš„MRCç»¼è¿°ï¼Œä¸€äº›æƒ³æ³•å¾ˆå¤§èƒ†ï¼Œä½†ä¸€äº›åœ°æ–¹æ²¡æœ‰è®²æ˜ç™½ã€‚</p>
</li>
<li><p>Recent Advances in Natural Language Inference: A Survey of Benchmarks, Resources, and Approaches ğŸ˜»<br><em>Shane Storks, Qiaozi Gao, Joyce Y. Chai</em><br>å¯¹äºï¼ˆå¹¿ä¹‰çš„ï¼‰Commonsense QAåšçš„ç»¼è¿°ã€‚</p>
</li>
</ul>
<h2 id="Machine-Reading-Comprehension-Dataset"><a href="#Machine-Reading-Comprehension-Dataset" class="headerlink" title="Machine Reading Comprehension Dataset"></a>Machine Reading Comprehension Dataset</h2><ul>
<li><p>SQuAD: 100,000+ Questions for Machine Comprehension of Text ğŸ˜»<br><em>Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang</em>, EMNLP 16<br>MRCé¢†åŸŸæœ€ç»å…¸çš„æ•°æ®é›†SQuADã€‚è¿™æ˜¯ä¸å«unanswerable questionçš„1.0ç‰ˆæœ¬ï¼Œé—®é¢˜æ¥æºäºwikipediaï¼Œäººå·¥æ ¹æ®æ–‡ç« æé—®é¢˜ã€‚</p>
</li>
<li><p>Know What You Donâ€™t Know: Unanswerable Questions for SQuAD ğŸ˜»<br><em>Pranav Rajpurkar, Robin Jia, Percy Liang</em>, ACL 18<br>SQuAD 2.0ï¼ŒåŠ å…¥äº†å¤§é‡unanswerable question</p>
</li>
<li><p>NewsQA: A Machine Comprehension Dataset<br><em>Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip Bachman, Kaheer Suleman</em><br>æ–‡ç« æ¥æºäºCNNï¼Œæé—®è€…åªèƒ½çœ‹åˆ°æ–°é—»çš„summary pointsï¼Œç­”æ¡ˆä»æ¥è‡ªæ–°é—»æ­£æ–‡ï¼Œä»è€Œé¿å…é—®é¢˜å’Œæ–‡ç« è¿‡äºç›¸ä¼¼ã€‚</p>
</li>
<li><p>ReCoRD: Bridging the Gap between Human and Machine Commonsense Reading Comprehension<br><em>Sheng Zhang, Xiaodong Liu, Jingjing Liu, Jianfeng Gao, Kevin Duh, Benjamin Van Durme</em><br>ä¸€ä¸ªclozeå½¢å¼çš„é˜…è¯»ç†è§£æ•°æ®é›†ã€‚æ–‡ç« æ˜¯æ–°é—»çš„å‰å‡ æ®µï¼Œä»æ–°é—»çš„å‰©ä½™éƒ¨åˆ†æŒ‘ä¸€ä¸ªå¥å­ï¼ŒæŒ–æ‰å¥å­ä¸­ä¸€ä¸ªå®ä½“å½“ä½œé—®é¢˜ã€‚</p>
</li>
<li><p>Natural Questions: A Benchmark for Question Answering Research ğŸ˜»<br><em>Google</em>, TACL 19<br>ä»¥æ•´ä¸ªç»´åŸºé¡µé¢ä¸ºæ–‡ç« ï¼Œæ–‡ç« è¾ƒé•¿ï¼ŒåŒæ—¶æ ‡æ³¨é•¿ç­”æ¡ˆå’ŒçŸ­ç­”æ¡ˆã€‚</p>
</li>
<li><p>BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions<br><em>Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, Kristina Toutanova</em>, NAACL 19<br>ç ”ç©¶è‡ªç„¶äº§ç”Ÿçš„yes/no questionsï¼Œåˆ¶ä½œäº†é˜…è¯»ç†è§£æ•°æ®é›†BoolQï¼Œå‘ç°ä»entailment dataè¿ç§»å­¦ä¹ åœ¨å®ƒä¸Šé¢è¡¨ç°è¾ƒå¥½ã€‚</p>
</li>
<li><p>QUOREF: A Reading Comprehension Dataset with Questions Requiring Coreferential Reasoning<br><em>Pradeep Dasigi, Nelson F. Liu, Ana MarasoviÄ‡, Noah A. Smith, Matt Gardner</em>, EMNLP 19<br>24k extractive MRC questions, æ–‡ç« æ¥è‡ªwiki(40%çš„æ–‡ç« æ˜¯ç”µå½±æƒ…èŠ‚æ¦‚è¦)ï¼Œéœ€è¦å…±æŒ‡æ¶ˆè§£ã€‚</p>
</li>
<li><p>DuoRC: Towards complex language understanding with paraphrased reading comprehension<br><em>Amrita Saha, Rahul Aralikatte, Mitesh M. Khapra, Karthik Sankaranarayanan</em>, ACL 18<br>åŸºäº7680å¯¹ç”µå½±æƒ…èŠ‚æ¦‚è¦(ä¸€ç¯‡æ¥è‡ªç»´åŸºï¼Œä¸€ç¯‡æ¥è‡ªimdb)ã€‚4 challenges: å¾ˆå¤šé—®é¢˜ä¸æ–‡ç« çš„lexical overlapä½ï¼›éœ€è¦background knowledgeå’Œcommonsense knowledgeï¼›å™è¿°æ€§çš„æ–‡ç« ç»å¸¸éœ€è¦ç»¼åˆå¤šå¥çš„å¤æ‚æ¨ç†ï¼›åŒ…å«no answerçš„é—®é¢˜ã€‚</p>
</li>
<li><p>DuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications<br><em>Baidu</em>, ACL18<br>ä¸­æ–‡MRCæ•°æ®é›†ã€‚</p>
</li>
</ul>
<h2 id="Commonsense-QA-Dataset"><a href="#Commonsense-QA-Dataset" class="headerlink" title="Commonsense QA Dataset"></a>Commonsense QA Dataset</h2><ul>
<li><p>COMMONSENSEQA: A Question Answering Challenge Targeting Commonsense Knowledge ğŸ˜»<br><em>Alon Talmor, Jonathan Herzig, Nicholas Lourie, Jonathan Berant</em>, NAACL 19<br>åŸºäºConceptNetåšçš„é€‰æ‹©é¢˜å½¢å¼çš„å¸¸è¯†é—®ç­”ã€‚</p>
</li>
<li><p>COSMOS QA: Machine Reading Comprehension with Contextual Commonsense Reasoning ğŸ˜»<br><em>Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, Yejin Choi</em>, EMNLP 19<br>é˜…è¯»ç†è§£å½¢å¼çš„é€‰æ‹©é¢˜å¸¸è¯†é—®ç­”ï¼Œéœ€è¦é€šè¿‡commonsense inferenceæ¥read between the linesã€‚</p>
</li>
</ul>
<h2 id="Other-QA-Dataset"><a href="#Other-QA-Dataset" class="headerlink" title="Other QA Dataset"></a>Other QA Dataset</h2><ul>
<li><p>GeoSQA: A Benchmark for Scenario-based Question Answering in the Geography Domain at High School<br><em>Zixian Huang, Yulin Shen, Xiao Li, Yuang Wei, Gong Cheng, Lin Zhou, Xinyu Dai, Yuzhong Qu</em>, EMNLP 19<br>é«˜è€ƒåœ°ç†é¢˜ã€‚å¦‚ä½•å¤„ç†é¢˜ç›®ä¸­çš„å›¾ï¼Ÿ</p>
</li>
<li><p>MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms<br>37,200ä¸ªæ•°å­¦é¢˜ï¼Œé™„æœ‰é€‰é¡¹å’Œè§£é¢˜è·¯å¾„ã€‚</p>
</li>
</ul>
<h2 id="Dataset-Analysis-amp-Model-Analysis"><a href="#Dataset-Analysis-amp-Model-Analysis" class="headerlink" title="Dataset Analysis &amp; Model Analysis"></a>Dataset Analysis &amp; Model Analysis</h2><ul>
<li><p>What Makes Reading Comprehension Questions Easier?<br><em>Saku Sugawara, Kentaro Inui, Satoshi Sekine, Akiko Aizawa</em>, EMNLP 18<br>åˆ†ææœ€è¿‘çš„12ä¸ªMRCæ•°æ®é›†ï¼Œé€šè¿‡å¯å‘å¼è§„åˆ™åˆ†å‰²æ•°æ®é›†ï¼Œç„¶åæ£€æŸ¥å„è‡ªçš„è¡¨ç°ï¼Œè®¤ä¸º<em>hard questions require knowledge inference and multiple-sentence reasoning</em>ã€‚</p>
</li>
<li><p>Adversarial Examples for Evaluating Reading Comprehension Systems ğŸ˜»<br><em>Robin Jia, Percy Liang</em>, EMNLP 19<br>å¯¹MRCè¿›è¡Œåæ€çš„æ¯”è¾ƒæ—©çš„ä¸€ç¯‡ã€‚é€šè¿‡åœ¨æ–‡ç« ç»“å°¾åŠ ä¸Šå¯¹æŠ—æ€§çš„å¥å­èƒ½è®©æ¨¡å‹å›ç­”é”™é—®é¢˜ã€‚</p>
</li>
<li><p>Do NLP Models Know Numbers? Probing Numeracy in Embeddings ğŸ˜»<br><em>Eric Wallace, Yizhong Wang, Sujian Li, Sameer Singh, Matt Gardner</em>, EMNLP 19<br>ç ”ç©¶å‘ç°state-of-the-artçš„QAæ¨¡å‹åœ¨DROPä¸Šä¹Ÿè¡¨ç°å‡ºå¾ˆå¥½çš„numerical reasoningèƒ½åŠ›ã€‚ä¸ºäº†ç†è§£è¿™ç§èƒ½åŠ›å¦‚ä½•äº§ç”Ÿï¼Œä½œè€…æ¢ç´¢äº†å„ç§embeddingæ–¹æ³•åœ¨list maximum, number encoding, additionä¸‰ä¸ªä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚å‘ç°standard embeddingsä¸­å­˜åœ¨ç€å¾ˆå¤§ç¨‹åº¦çš„numeracyï¼Œcharacter-level embeddingså¯¹numeracyçš„è¡¨ç¤ºå¾ˆç²¾ç¡®ã€‚</p>
</li>
</ul>
<h2 id="QA-Model"><a href="#QA-Model" class="headerlink" title="QA Model"></a>QA Model</h2><ul>
<li><p>Bidirectional Attention Flow for Machine Comprehension ğŸ˜»<br><em>Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi</em>, ICLR 17<br>åŸºäºæ–‡ç« å’Œé—®é¢˜åŒå‘æ³¨æ„åŠ›çš„BiDAFæ¨¡å‹ã€‚æ˜¯MRCä¸­åŸºäºæ³¨æ„åŠ›æœºåˆ¶æœ€ç»å…¸çš„æ¨¡å‹ã€‚</p>
</li>
<li><p>Latent Retrieval for Weakly Supervised Open Domain Question Answering<br><em>Kenton Lee, Ming-Wei Chang, Kristina Toutanova</em>, ACL 19<br>æäº†ä¸€ä¸ªOpen Domain QAçš„ç«¯åˆ°ç«¯æ¨¡å‹ã€‚</p>
<p><strong>ä¸‹é¢æ˜¯å¯¹äºConversational MRCçš„æ–¹æ³•ï¼š</strong></p>
</li>
<li><p>GRAPHFLOW: Exploiting Conversation Flow with Graph Neural Networks for Conversational Machine Comprehension<br><em>Yu Chen, Lingfei Wu, Mohammed J. Zaki</em><br>åšconversational MRCçš„ï¼Œæ•è·å¯¹è¯ä¸­çš„conversational flowï¼šå°†conversational flowå»ºæ¨¡æˆå¯¹è¯ä¸­çš„ä¸€ç³»åˆ—latent statesã€‚</p>
</li>
<li><p>Answering Conversational Questions on Structured Data without Logical Forms<br><em>Thomas MÃ¼ller, Francesco Piccinno, Massimo Nicosia, Peter Shaw, Yasemin Altun</em>, EMNLP 19<br>æœé›†äº† åŒ…å«6kä¸ªå¯¹äºç»´åŸºä¸Šçš„åŠç»“æ„åŒ–è¡¨æ ¼è¿›è¡Œè¯¢é—®çš„é—®é¢˜åºåˆ— çš„æ•°æ®é›†ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ— éœ€logical fromsçš„weakly supervised semantic parsingæ¨¡å‹ã€‚</p>
</li>
<li><p>Technical report on Conversational Question Answering<br>åœ¨CoQAä¸Šä½¿ç”¨RoBERTa + AT(Adversarial Training) + KD(Knowledge Distillation)ï¼Œè¾¾åˆ°90.4 F1ã€‚</p>
<p><strong>ä¸‹é¢æ˜¯å¯¹äºMulti-hop MRCçš„æ–¹æ³•ï¼š</strong></p>
</li>
<li><p>Token-level Dynamic Self-Attention Network for Multi-Passage Reading Comprehension<br><em>Yimeng Zhuang, Huadong Wang</em>, ACL 19<br>åœ¨token-levelå¤„ç†cross-passage infomationï¼Œèƒ½å¤ŸåŠ¨æ€åœ°ä»åºåˆ—ä¸­é€‰å–é‡è¦çš„tokenï¼Œè¾¾åˆ°speed, memoryå’Œaccuracyçš„å¹³è¡¡ã€‚</p>
</li>
<li><p>Answering Complex Open-domain Questions Through Iterative Query Generation<br><em>Peng Qi, Xiaowen Lin, Leo Mehr, Zijian Wang, Christopher D. Manning</em>, EMNLP 19<br>åœ¨æ¯ä¸€æ­¥ï¼Œåˆ©ç”¨ä¹‹å‰hopçš„IRç»“æœç”Ÿæˆä¸€ä¸ªæ–°çš„è‡ªç„¶è¯­è¨€queryï¼Œç”¨off-the-shelfçš„IRç³»ç»Ÿå»retriveæ–°çš„è¯æ®æ¥å›ç­”é—®é¢˜ã€‚</p>
</li>
<li><p>Cognitive Graph for Multi-Hop Reading Comprehension at Scale<br><em>Ming Ding, Chang Zhou, Qibin Chen, Hongxia Yang, Jie Tang</em>, ACL 19<br>æ ¹æ®å¿ƒç†å­¦ä¸­çš„Dual process theoryï¼Œå¤§è„‘å…ˆæ— æ„è¯†åœ°ã€éšæ€§åœ°ã€ç›´è§‰åœ°åˆ©ç”¨æ³¨æ„åŠ›æ£€ç´¢ç›¸å…³ä¿¡æ¯(system 1)ï¼Œç„¶åæœ‰æ„è¯†åœ°ã€æ˜¾æ€§åœ°ã€å¯æ§åœ°è¿›è¡Œæ¨ç†(system 2)ã€‚</p>
<p><strong>ä¸‹é¢æ˜¯å¯¹äºCommonsense QAçš„æ–¹æ³•å’Œä¸€äº›å¼•å…¥External Knowledgeçš„æ–¹æ³•ï¼š</strong></p>
</li>
<li><p>Augmenting Neural Networks with First-order Logic<br><em>Tao Li, Vivek Srikumar</em>, ACL19<br>ç›´æ¥æŠŠä¸€é˜¶é€»è¾‘è¡¨ç¤ºçš„å¤–éƒ¨çŸ¥è¯†ï¼ˆè¿™é‡Œç”¨äº†ConceptNetï¼‰åµŒå…¥åˆ°ç¥ç»ç½‘ç»œæ¶æ„ä¸­ï¼Œè€Œä»ç„¶ä¿æŒç«¯åˆ°ç«¯çš„è®­ç»ƒæ–¹å¼ï¼ŒåŒæ—¶ä¾é è¿™äº›å¤–éƒ¨è§„åˆ™æ¥å‡å°‘å¯¹æ•°æ®çš„ä¾èµ–ã€‚</p>
</li>
<li><p>Align, Mask and Select: A Simple Method for Incorporating Commonsense Knowledge into Language Representation Models<br><em>Zhi-Xiu Ye, Qian Chen, Wen Wang, Zhen-Hua Ling</em><br>ç°å­˜é¢„è®­ç»ƒçš„è¯­è¨€è¡¨ç¤ºæ¨¡å‹å¾ˆå°‘è€ƒè™‘ç›´æ¥å°†å¸¸è¯†çŸ¥è¯†åµŒå…¥ã€‚æœ¬æ–‡ç”¨â€œalign, mask, and selectâ€çš„æ–¹æ³•æ„é€ æœ‰å…³å¸¸è¯†çš„æ•°æ®é›†ï¼Œå¹¶åœ¨å®ƒä¸Šé¢é¢„è®­ç»ƒBERTï¼Œä»è€Œå°†å¸¸è¯†çŸ¥è¯†å¼•å…¥åˆ°è¯­è¨€è¡¨ç¤ºæ¨¡å‹ã€‚</p>
</li>
<li><p>Explicit Utilization of General Knowledge in Machine Reading Comprehension ğŸ˜»<br><em>Chao Wang, Hui Jiang</em>, ACL 19<br>ç°æœ‰MRCæ¨¡å‹ä¸äººç±»ä¹‹é—´çš„gapä½“ç°åœ¨å¯¹æ•°æ®çš„éœ€æ±‚å’ŒæŠµå¾¡å™ªå£°çš„é²æ£’æ€§ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸¤ä¸ªé—®é¢˜ï¼Œä½œè€…ä½¿ç”¨WordNetä»passage-question pairä¸­æŠ½å–è¯é—´è¯­ä¹‰å…³ç³»ä½œä¸ºgeneral knowledgeï¼Œæ¥è¾…åŠ©ç«¯åˆ°ç«¯æ¨¡å‹ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚</p>
</li>
<li><p>Enhancing Pre-Trained Language Representations with Rich Knowledge for Machine Reading Comprehension<br><em>An Yang, Quan Wang, Jing Liu, Kai Liu, Yajuan Lyu, Hua Wu, Qiaoqiao She, Sujian Li</em>, ACL 19<br>ä½¿ç”¨WordNetå’ŒNELLä¸¤ä¸ªKBä½œä¸ºMRCçš„å¤–éƒ¨çŸ¥è¯†ï¼Œé€šè¿‡æ³¨æ„åŠ›æœºåˆ¶é€‰å–éœ€è¦çš„çŸ¥è¯†æ³¨å…¥åˆ°BERTä¸­ï¼Œåœ¨Recordå’Œsquad1.1ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ•ˆæœã€‚</p>
</li>
<li><p>Careful Selection of Knowledge to solve Open Book Question Answering<br><em>Pratyay Banerjee, Kuntal Kumar Pal, Arindam Mitra, Chitta Baral</em><br>ç”¨æ¯”è¾ƒIRçš„æ–¹æ³•åšOpenBookQAã€‚</p>
</li>
<li><p>KagNet: Knowledge-Aware Graph Networks for Commonsense Reasoning ğŸ˜»<br>ä¸€ç§ç±»ä¼¼DBQAçš„æ–¹æ³•ï¼Œåˆ©ç”¨ConceptNetå»ºå›¾åšCOMMONSENSEQAæ•°æ®é›†ã€‚</p>
<p><strong>ä¸‹é¢æ˜¯å¯¹äºDiscrete Reasoningå’ŒMulti-span Extractionçš„æ–¹æ³•ï¼ˆä¸»è¦æ˜¯é’ˆå¯¹DROPæ•°æ®é›†ï¼‰ï¼š</strong><br>DROPæ•°æ®é›†ç­”æ¡ˆåŒ…å«å¤šç§ç±»å‹ï¼šdataã€numberã€text span(s)ï¼Œéœ€è¦numerical operationsæ¯”å¦‚addingã€ sortingã€countingã€‚</p>
</li>
<li><p>A Multi-Type Multi-Span Network for Reading Comprehension that Requires Discrete Reasoning<br><em>Minghao Hu, Yuxing Peng, Zhen Huang, Dongsheng Li</em>, EMNLP 19</p>
</li>
<li><p>Giving BERT a Calculator: Finding Operations and Arguments with Reading Comprehension ğŸ˜»<br><em>Google</em>, EMNLP 19</p>
</li>
<li><p>A Discrete Hard EM Approach for Weakly Supervised Question Answering<br><em>Sewon Min, Danqi Chen, Hannaneh Hajishirzi, Luke Zettlemoyer</em>, EMNLP 19</p>
</li>
<li><p>Tag-based Multi-Span Extraction in Reading Comprehension<br><em>Avia Efrat, Elad Segal, Mor Shoham</em></p>
</li>
</ul>
<h3 id="Unanswerable-Questions"><a href="#Unanswerable-Questions" class="headerlink" title="Unanswerable Questions"></a>Unanswerable Questions</h3><ul>
<li>Relation Module for Non-answerable Prediction on Reading Comprehension<br><em>DiDi</em><br>é€šè¿‡å¢åŠ relation moduleæ¥æé«˜MRCæ¨¡å‹åˆ¤æ–­é—®é¢˜æ˜¯å¦æœ‰ç­”æ¡ˆçš„èƒ½åŠ›ã€‚</li>
</ul>
<h2 id="Transfer-Learning-amp-Multi-task-Learning"><a href="#Transfer-Learning-amp-Multi-task-Learning" class="headerlink" title="Transfer Learning &amp; Multi-task Learning"></a>Transfer Learning &amp; Multi-task Learning</h2><ul>
<li><p>MultiQA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension ğŸ˜»<br><em>Alon Talmor, Jonathan Berant</em>, ACL 19<br>ç ”ç©¶å„ä¸ªMRCæ•°æ®é›†èƒ½å¦äº’ç›¸æ³›åŒ–ã€‚å®éªŒåšäº†å¾ˆå¤šã€‚</p>
</li>
<li><p>Multi-task Learning with Sample Re-weighting for Machine Reading Comprehension<br><em>Yichong Xu, Xiaodong Liu, Yelong Shen, Jingjing Liu, Jianfeng Gao</em>, NAACL 19<br>é€šè¿‡å°†å¤šä¸ªä»»åŠ¡çš„æ•°æ®é›†ä½¿ç”¨ç²¾ç»†çš„é‡‡æ ·ç»“åˆåœ¨ä¸€èµ·è®­ç»ƒï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–æ€§ã€‚</p>
</li>
<li><p>Unsupervised Domain Adaptation on Reading Comprehension<br>AAAI 20</p>
</li>
</ul>
<h2 id="Question-Generation"><a href="#Question-Generation" class="headerlink" title="Question Generation"></a>Question Generation</h2><ul>
<li>Learning to Ask Unanswerable Questions for Machine Reading Comprehension ğŸ˜»<br><em>Haichao Zhu, Li Dong, Furu Wei, Wenhui Wang, Bing Qin, Ting Liu</em>, ACL 19<br>é€šè¿‡ä¸€ç§pair2sequenceçš„æ–¹å¼ï¼Œç”±å¯å›ç­”é—®é¢˜å’Œæ®µè½ç”Ÿæˆä¸å¯å›ç­”é—®é¢˜ã€‚ç”Ÿæˆçš„ä¸å¯å›ç­”é—®é¢˜å½“ä½œdata augmentationæå‡äº†BERTçš„è¡¨ç°ã€‚</li>
</ul>
<h2 id="Text-Matching"><a href="#Text-Matching" class="headerlink" title="Text Matching"></a>Text Matching</h2><ul>
<li><p>MIX: Multi-Channel Information Crossing for Text Matching<br><em>Tencent</em>, KDD 18<br>ä»å¤šç§ç»†ç²’åº¦è¿›è¡Œæ–‡æœ¬åŒ¹é…ã€‚</p>
</li>
<li><p>Enhanced LSTM for Natural Language Inference ğŸ˜»<br><em>Qian Chen, Xiaodan Zhu, Zhenhua Ling, Si Wei, Hui Jiang, Diana Inkpen</em>, ACL 17<br>ä¸€ä¸ªåŸºäºBiLSTM + Attentionçš„å¾ˆæœ‰æ•ˆçš„æ–‡æœ¬åŒ¹é…æ¨¡å‹ESIMã€‚</p>
</li>
</ul>
<h2 id="NLI-Dataset"><a href="#NLI-Dataset" class="headerlink" title="NLI Dataset"></a>NLI Dataset</h2><ul>
<li>Adversarial NLI: A New Benchmark for Natural Language Understanding ğŸ˜»<br><em>Facebook</em><br>é€šè¿‡è¿­ä»£çš„ã€å¯¹æŠ—æ€§çš„äººç±»-æ¨¡å‹å¾ªç¯ï¼Œå¾—åˆ°äº†ä¸€ä¸ªå¤§è§„æ¨¡çš„NLIæ•°æ®é›†ã€‚åœ¨è¿™ä¸ªæ–°æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹åœ¨å¾ˆå¤šNLIæ•°æ®é›†ä¸Šè¾¾åˆ°state-of-the-artè¡¨ç°ã€‚è¿™ä¸ªæ•°æ®é›†ä¹Ÿè¯´æ˜äº†éä¸“å®¶æ ‡æ³¨è€…ä¹Ÿèƒ½æˆåŠŸæ‰¾åˆ°æ¨¡å‹ä»¬çš„ç¼ºç‚¹ã€‚æ•°æ®æ”¶é›†çš„æ–¹æ³•å¯ä»¥è¿ç”¨äºnever-ending learningï¼Œå¯ä»¥æˆä¸ºä¸€ä¸ªmoving targetï¼Œè€Œéä¸€ä¸ªå¿«é€Ÿé¥±å’Œçš„é™æ€benchmarkã€‚æ€»å¾—æ¥è¯´ï¼Œè§£å†³äº†ç°å­˜æ•°æ®é›†benchmark longevityå’Œrobustnessä¸¤ä¸ªé—®é¢˜ã€‚</li>
</ul>
<h2 id="Story-Ending-Prediction"><a href="#Story-Ending-Prediction" class="headerlink" title="Story Ending Prediction"></a>Story Ending Prediction</h2><p>éƒ½æ˜¯åšStory Cloze Testè¿™ä¸ªæ•°æ®é›†çš„ã€‚</p>
<ul>
<li>LSDSem 2017: Exploring Data Generation Methods for the Story Cloze Test<br>ç”¨äº†ä¸€ä¸ªfeature-basedçš„æ–¹æ³•ï¼Œæ•ˆæœè¿˜æŒºå¥½</li>
<li>Improving Language Understanding by Generative Pre-Training</li>
<li>A Multi-Attention based Neural Network with External Knowledge for Story Ending Predicting Task<br>ç”¨äº†SemLM</li>
<li>An RNN-based Binary Classifier for the Story Cloze Test<br>ç”¨äº†Skip-thought</li>
<li>A Simple and Effective Approach to the Story Cloze Test<br>ç”¨äº†Skip-thought</li>
<li>Story Ending Selection by Finding Hints from Pairwise Candidate Endings<br>éš”å£çš„å·¥ä½œï¼Œå°†ä¸¤ä¸ªé€‰é¡¹åŒæ—¶æ”¾å…¥æ¨¡å‹è¿›è¡ŒåŒºåˆ†</li>
<li>Find a Reasonable Ending for Stories: Does Logic Relation Help the Story Cloze Test? ğŸ˜»<br>AAAI 19ã€‚ç”¨NLIæ•°æ®é¢„è®­ç»ƒï¼Œç”¨é€»è¾‘çŸ¥è¯†è¾…åŠ©åˆ¤æ–­ã€‚</li>
<li>Narrative Modeling with Memory Chains and Semantic Supervision</li>
<li>Discriminative Sentence Modeling for Story Ending Prediction<br>AAAI 20</li>
</ul>
</div></article></div><div id="disqus_thread"></div></div><script>var disqus_shortname = 'Lucius';
var disqus_identifier = '2020/01/11/2019ï¼Œæˆ‘è¯»è¿‡çš„è®ºæ–‡/';
var disqus_title = '2019ï¼Œæˆ‘è¯»è¿‡çš„è®ºæ–‡';
var disqus_url = 'http://luciusssss.github.io/2020/01/11/2019ï¼Œæˆ‘è¯»è¿‡çš„è®ºæ–‡/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//Lucius.disqus.com/count.js" async></script></main><footer class="footer-container"><div class="paginator"><a href="/2020/01/11/hello-world/" class="next">NEXT</a></div><div class="copyright"><p>Â© 2020 <a href="http://luciusssss.github.io">Lucius</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/AngryPowman/hexo-theme-prontera" target="_blank">hexo-theme-prontera</a>.</p></div></footer></body></html>