<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 2019，我读过的论文 · Blog - Lucius</title><meta name="description" content="2019，我读过的论文 - Lucius"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/css/prontera.css"><link rel="search" type="application/opensearchdescription+xml" href="http://luciusssss.github.io/atom.xml" title="Blog - Lucius"><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="Blog - Lucius" type="application/atom+xml">
</head><body><header class="feature-header"><nav class="component-nav"><ul><div class="logo-container"><a href="/"><h2 class="title">Blog - Lucius</h2></a></div><a href="/" target="_self" class="li component-nav-item"><p>INDEX</p></a><a href="/archives" target="_self" class="li component-nav-item"><p>ARCHIVES</p></a><a href="/about" target="_self" class="li component-nav-item"><p>ABOUT</p></a><ul class="shortcut-icons"><a href="https://github.com/luciusssss" target="_blank"><img src="/images/github.svg" class="icon"></a></ul></ul></nav></header><main class="container"><div id="post-container"><div class="post"><article class="post-block"><h1 class="post-title">2019，我读过的论文</h1><div class="post-info">Jan 11, 2020</div><div class="post-content"><p>去年开始认真读论文还是从7月开始，主要读了很多Question Answering的论文，其中又以Machine Reading Comprehension为主，大概了解了QA这个领域在做些什么。<br>这里我把去年读过的论文简单列一下。其中我觉得值得一读的论文我会打上😻。<br>阅读过程中尤其感谢LAI Yuxuan师兄的指导！</p>
<a id="more"></a>

<h2 id="Survey"><a href="#Survey" class="headerlink" title="Survey"></a>Survey</h2><ul>
<li><p>NEURAL READING COMPREHENSION AND BEYOND 😻<br><em>Chen Danqi</em><br>陈丹琦的博士毕业论文，一篇对MRC比较全面且易懂的综述。</p>
</li>
<li><p>Neural Machine Reading Comprehension: Methods and Trends<br><em>Shanshan Liu, Xin Zhang, Sheng Zhang, Hui Wang, Weiming Zhang</em><br>国防科大的MRC综述，一些想法很大胆，但一些地方没有讲明白。</p>
</li>
<li><p>Recent Advances in Natural Language Inference: A Survey of Benchmarks, Resources, and Approaches 😻<br><em>Shane Storks, Qiaozi Gao, Joyce Y. Chai</em><br>对于（广义的）Commonsense QA做的综述。</p>
</li>
</ul>
<h2 id="Machine-Reading-Comprehension-Dataset"><a href="#Machine-Reading-Comprehension-Dataset" class="headerlink" title="Machine Reading Comprehension Dataset"></a>Machine Reading Comprehension Dataset</h2><ul>
<li><p>SQuAD: 100,000+ Questions for Machine Comprehension of Text 😻<br><em>Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang</em>, EMNLP 16<br>MRC领域最经典的数据集SQuAD。这是不含unanswerable question的1.0版本，问题来源于wikipedia，人工根据文章提问题。</p>
</li>
<li><p>Know What You Don’t Know: Unanswerable Questions for SQuAD 😻<br><em>Pranav Rajpurkar, Robin Jia, Percy Liang</em>, ACL 18<br>SQuAD 2.0，加入了大量unanswerable question</p>
</li>
<li><p>NewsQA: A Machine Comprehension Dataset<br><em>Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip Bachman, Kaheer Suleman</em><br>文章来源于CNN，提问者只能看到新闻的summary points，答案从来自新闻正文，从而避免问题和文章过于相似。</p>
</li>
<li><p>ReCoRD: Bridging the Gap between Human and Machine Commonsense Reading Comprehension<br><em>Sheng Zhang, Xiaodong Liu, Jingjing Liu, Jianfeng Gao, Kevin Duh, Benjamin Van Durme</em><br>一个cloze形式的阅读理解数据集。文章是新闻的前几段，从新闻的剩余部分挑一个句子，挖掉句子中一个实体当作问题。</p>
</li>
<li><p>Natural Questions: A Benchmark for Question Answering Research 😻<br><em>Google</em>, TACL 19<br>以整个维基页面为文章，文章较长，同时标注长答案和短答案。</p>
</li>
<li><p>BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions<br><em>Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, Kristina Toutanova</em>, NAACL 19<br>研究自然产生的yes/no questions，制作了阅读理解数据集BoolQ，发现从entailment data迁移学习在它上面表现较好。</p>
</li>
<li><p>QUOREF: A Reading Comprehension Dataset with Questions Requiring Coreferential Reasoning<br><em>Pradeep Dasigi, Nelson F. Liu, Ana Marasović, Noah A. Smith, Matt Gardner</em>, EMNLP 19<br>24k extractive MRC questions, 文章来自wiki(40%的文章是电影情节概要)，需要共指消解。</p>
</li>
<li><p>DuoRC: Towards complex language understanding with paraphrased reading comprehension<br><em>Amrita Saha, Rahul Aralikatte, Mitesh M. Khapra, Karthik Sankaranarayanan</em>, ACL 18<br>基于7680对电影情节概要(一篇来自维基，一篇来自imdb)。4 challenges: 很多问题与文章的lexical overlap低；需要background knowledge和commonsense knowledge；叙述性的文章经常需要综合多句的复杂推理；包含no answer的问题。</p>
</li>
<li><p>DuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications<br><em>Baidu</em>, ACL18<br>中文MRC数据集。</p>
</li>
</ul>
<h2 id="Commonsense-QA-Dataset"><a href="#Commonsense-QA-Dataset" class="headerlink" title="Commonsense QA Dataset"></a>Commonsense QA Dataset</h2><ul>
<li><p>COMMONSENSEQA: A Question Answering Challenge Targeting Commonsense Knowledge 😻<br><em>Alon Talmor, Jonathan Herzig, Nicholas Lourie, Jonathan Berant</em>, NAACL 19<br>基于ConceptNet做的选择题形式的常识问答。</p>
</li>
<li><p>COSMOS QA: Machine Reading Comprehension with Contextual Commonsense Reasoning 😻<br><em>Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, Yejin Choi</em>, EMNLP 19<br>阅读理解形式的选择题常识问答，需要通过commonsense inference来read between the lines。</p>
</li>
</ul>
<h2 id="Other-QA-Dataset"><a href="#Other-QA-Dataset" class="headerlink" title="Other QA Dataset"></a>Other QA Dataset</h2><ul>
<li><p>GeoSQA: A Benchmark for Scenario-based Question Answering in the Geography Domain at High School<br><em>Zixian Huang, Yulin Shen, Xiao Li, Yuang Wei, Gong Cheng, Lin Zhou, Xinyu Dai, Yuzhong Qu</em>, EMNLP 19<br>高考地理题。如何处理题目中的图？</p>
</li>
<li><p>MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms<br>37,200个数学题，附有选项和解题路径。</p>
</li>
</ul>
<h2 id="Dataset-Analysis-amp-Model-Analysis"><a href="#Dataset-Analysis-amp-Model-Analysis" class="headerlink" title="Dataset Analysis &amp; Model Analysis"></a>Dataset Analysis &amp; Model Analysis</h2><ul>
<li><p>What Makes Reading Comprehension Questions Easier?<br><em>Saku Sugawara, Kentaro Inui, Satoshi Sekine, Akiko Aizawa</em>, EMNLP 18<br>分析最近的12个MRC数据集，通过启发式规则分割数据集，然后检查各自的表现，认为<em>hard questions require knowledge inference and multiple-sentence reasoning</em>。</p>
</li>
<li><p>Adversarial Examples for Evaluating Reading Comprehension Systems 😻<br><em>Robin Jia, Percy Liang</em>, EMNLP 19<br>对MRC进行反思的比较早的一篇。通过在文章结尾加上对抗性的句子能让模型回答错问题。</p>
</li>
<li><p>Do NLP Models Know Numbers? Probing Numeracy in Embeddings 😻<br><em>Eric Wallace, Yizhong Wang, Sujian Li, Sameer Singh, Matt Gardner</em>, EMNLP 19<br>研究发现state-of-the-art的QA模型在DROP上也表现出很好的numerical reasoning能力。为了理解这种能力如何产生，作者探索了各种embedding方法在list maximum, number encoding, addition三个任务上的表现。发现standard embeddings中存在着很大程度的numeracy，character-level embeddings对numeracy的表示很精确。</p>
</li>
</ul>
<h2 id="QA-Model"><a href="#QA-Model" class="headerlink" title="QA Model"></a>QA Model</h2><ul>
<li><p>Bidirectional Attention Flow for Machine Comprehension 😻<br><em>Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi</em>, ICLR 17<br>基于文章和问题双向注意力的BiDAF模型。是MRC中基于注意力机制最经典的模型。</p>
</li>
<li><p>Latent Retrieval for Weakly Supervised Open Domain Question Answering<br><em>Kenton Lee, Ming-Wei Chang, Kristina Toutanova</em>, ACL 19<br>提了一个Open Domain QA的端到端模型。</p>
<p><strong>下面是对于Conversational MRC的方法：</strong></p>
</li>
<li><p>GRAPHFLOW: Exploiting Conversation Flow with Graph Neural Networks for Conversational Machine Comprehension<br><em>Yu Chen, Lingfei Wu, Mohammed J. Zaki</em><br>做conversational MRC的，捕获对话中的conversational flow：将conversational flow建模成对话中的一系列latent states。</p>
</li>
<li><p>Answering Conversational Questions on Structured Data without Logical Forms<br><em>Thomas Müller, Francesco Piccinno, Massimo Nicosia, Peter Shaw, Yasemin Altun</em>, EMNLP 19<br>搜集了 包含6k个对于维基上的半结构化表格进行询问的问题序列 的数据集，并提出了一个无需logical froms的weakly supervised semantic parsing模型。</p>
</li>
<li><p>Technical report on Conversational Question Answering<br>在CoQA上使用RoBERTa + AT(Adversarial Training) + KD(Knowledge Distillation)，达到90.4 F1。</p>
<p><strong>下面是对于Multi-hop MRC的方法：</strong></p>
</li>
<li><p>Token-level Dynamic Self-Attention Network for Multi-Passage Reading Comprehension<br><em>Yimeng Zhuang, Huadong Wang</em>, ACL 19<br>在token-level处理cross-passage infomation，能够动态地从序列中选取重要的token，达到speed, memory和accuracy的平衡。</p>
</li>
<li><p>Answering Complex Open-domain Questions Through Iterative Query Generation<br><em>Peng Qi, Xiaowen Lin, Leo Mehr, Zijian Wang, Christopher D. Manning</em>, EMNLP 19<br>在每一步，利用之前hop的IR结果生成一个新的自然语言query，用off-the-shelf的IR系统去retrive新的证据来回答问题。</p>
</li>
<li><p>Cognitive Graph for Multi-Hop Reading Comprehension at Scale<br><em>Ming Ding, Chang Zhou, Qibin Chen, Hongxia Yang, Jie Tang</em>, ACL 19<br>根据心理学中的Dual process theory，大脑先无意识地、隐性地、直觉地利用注意力检索相关信息(system 1)，然后有意识地、显性地、可控地进行推理(system 2)。</p>
<p><strong>下面是对于Commonsense QA的方法和一些引入External Knowledge的方法：</strong></p>
</li>
<li><p>Augmenting Neural Networks with First-order Logic<br><em>Tao Li, Vivek Srikumar</em>, ACL19<br>直接把一阶逻辑表示的外部知识（这里用了ConceptNet）嵌入到神经网络架构中，而仍然保持端到端的训练方式，同时依靠这些外部规则来减少对数据的依赖。</p>
</li>
<li><p>Align, Mask and Select: A Simple Method for Incorporating Commonsense Knowledge into Language Representation Models<br><em>Zhi-Xiu Ye, Qian Chen, Wen Wang, Zhen-Hua Ling</em><br>现存预训练的语言表示模型很少考虑直接将常识知识嵌入。本文用“align, mask, and select”的方法构造有关常识的数据集，并在它上面预训练BERT，从而将常识知识引入到语言表示模型。</p>
</li>
<li><p>Explicit Utilization of General Knowledge in Machine Reading Comprehension 😻<br><em>Chao Wang, Hui Jiang</em>, ACL 19<br>现有MRC模型与人类之间的gap体现在对数据的需求和抵御噪声的鲁棒性。为了缓解这两个问题，作者使用WordNet从passage-question pair中抽取词间语义关系作为general knowledge，来辅助端到端模型中的注意力机制。</p>
</li>
<li><p>Enhancing Pre-Trained Language Representations with Rich Knowledge for Machine Reading Comprehension<br><em>An Yang, Quan Wang, Jing Liu, Kai Liu, Yajuan Lyu, Hua Wu, Qiaoqiao She, Sujian Li</em>, ACL 19<br>使用WordNet和NELL两个KB作为MRC的外部知识，通过注意力机制选取需要的知识注入到BERT中，在Record和squad1.1上取得了很好的效果。</p>
</li>
<li><p>Careful Selection of Knowledge to solve Open Book Question Answering<br><em>Pratyay Banerjee, Kuntal Kumar Pal, Arindam Mitra, Chitta Baral</em><br>用比较IR的方法做OpenBookQA。</p>
</li>
<li><p>KagNet: Knowledge-Aware Graph Networks for Commonsense Reasoning 😻<br>一种类似DBQA的方法，利用ConceptNet建图做COMMONSENSEQA数据集。</p>
<p><strong>下面是对于Discrete Reasoning和Multi-span Extraction的方法（主要是针对DROP数据集）：</strong><br>DROP数据集答案包含多种类型：data、number、text span(s)，需要numerical operations比如adding、 sorting、counting。</p>
</li>
<li><p>A Multi-Type Multi-Span Network for Reading Comprehension that Requires Discrete Reasoning<br><em>Minghao Hu, Yuxing Peng, Zhen Huang, Dongsheng Li</em>, EMNLP 19</p>
</li>
<li><p>Giving BERT a Calculator: Finding Operations and Arguments with Reading Comprehension 😻<br><em>Google</em>, EMNLP 19</p>
</li>
<li><p>A Discrete Hard EM Approach for Weakly Supervised Question Answering<br><em>Sewon Min, Danqi Chen, Hannaneh Hajishirzi, Luke Zettlemoyer</em>, EMNLP 19</p>
</li>
<li><p>Tag-based Multi-Span Extraction in Reading Comprehension<br><em>Avia Efrat, Elad Segal, Mor Shoham</em></p>
</li>
</ul>
<h3 id="Unanswerable-Questions"><a href="#Unanswerable-Questions" class="headerlink" title="Unanswerable Questions"></a>Unanswerable Questions</h3><ul>
<li>Relation Module for Non-answerable Prediction on Reading Comprehension<br><em>DiDi</em><br>通过增加relation module来提高MRC模型判断问题是否有答案的能力。</li>
</ul>
<h2 id="Transfer-Learning-amp-Multi-task-Learning"><a href="#Transfer-Learning-amp-Multi-task-Learning" class="headerlink" title="Transfer Learning &amp; Multi-task Learning"></a>Transfer Learning &amp; Multi-task Learning</h2><ul>
<li><p>MultiQA: An Empirical Investigation of Generalization and Transfer in Reading Comprehension 😻<br><em>Alon Talmor, Jonathan Berant</em>, ACL 19<br>研究各个MRC数据集能否互相泛化。实验做了很多。</p>
</li>
<li><p>Multi-task Learning with Sample Re-weighting for Machine Reading Comprehension<br><em>Yichong Xu, Xiaodong Liu, Yelong Shen, Jingjing Liu, Jianfeng Gao</em>, NAACL 19<br>通过将多个任务的数据集使用精细的采样结合在一起训练，提高模型的泛化性。</p>
</li>
<li><p>Unsupervised Domain Adaptation on Reading Comprehension<br>AAAI 20</p>
</li>
</ul>
<h2 id="Question-Generation"><a href="#Question-Generation" class="headerlink" title="Question Generation"></a>Question Generation</h2><ul>
<li>Learning to Ask Unanswerable Questions for Machine Reading Comprehension 😻<br><em>Haichao Zhu, Li Dong, Furu Wei, Wenhui Wang, Bing Qin, Ting Liu</em>, ACL 19<br>通过一种pair2sequence的方式，由可回答问题和段落生成不可回答问题。生成的不可回答问题当作data augmentation提升了BERT的表现。</li>
</ul>
<h2 id="Text-Matching"><a href="#Text-Matching" class="headerlink" title="Text Matching"></a>Text Matching</h2><ul>
<li><p>MIX: Multi-Channel Information Crossing for Text Matching<br><em>Tencent</em>, KDD 18<br>从多种细粒度进行文本匹配。</p>
</li>
<li><p>Enhanced LSTM for Natural Language Inference 😻<br><em>Qian Chen, Xiaodan Zhu, Zhenhua Ling, Si Wei, Hui Jiang, Diana Inkpen</em>, ACL 17<br>一个基于BiLSTM + Attention的很有效的文本匹配模型ESIM。</p>
</li>
</ul>
<h2 id="NLI-Dataset"><a href="#NLI-Dataset" class="headerlink" title="NLI Dataset"></a>NLI Dataset</h2><ul>
<li>Adversarial NLI: A New Benchmark for Natural Language Understanding 😻<br><em>Facebook</em><br>通过迭代的、对抗性的人类-模型循环，得到了一个大规模的NLI数据集。在这个新数据集上训练的模型在很多NLI数据集上达到state-of-the-art表现。这个数据集也说明了非专家标注者也能成功找到模型们的缺点。数据收集的方法可以运用于never-ending learning，可以成为一个moving target，而非一个快速饱和的静态benchmark。总得来说，解决了现存数据集benchmark longevity和robustness两个问题。</li>
</ul>
<h2 id="Story-Ending-Prediction"><a href="#Story-Ending-Prediction" class="headerlink" title="Story Ending Prediction"></a>Story Ending Prediction</h2><p>都是做Story Cloze Test这个数据集的。</p>
<ul>
<li>LSDSem 2017: Exploring Data Generation Methods for the Story Cloze Test<br>用了一个feature-based的方法，效果还挺好</li>
<li>Improving Language Understanding by Generative Pre-Training</li>
<li>A Multi-Attention based Neural Network with External Knowledge for Story Ending Predicting Task<br>用了SemLM</li>
<li>An RNN-based Binary Classifier for the Story Cloze Test<br>用了Skip-thought</li>
<li>A Simple and Effective Approach to the Story Cloze Test<br>用了Skip-thought</li>
<li>Story Ending Selection by Finding Hints from Pairwise Candidate Endings<br>隔壁的工作，将两个选项同时放入模型进行区分</li>
<li>Find a Reasonable Ending for Stories: Does Logic Relation Help the Story Cloze Test? 😻<br>AAAI 19。用NLI数据预训练，用逻辑知识辅助判断。</li>
<li>Narrative Modeling with Memory Chains and Semantic Supervision</li>
<li>Discriminative Sentence Modeling for Story Ending Prediction<br>AAAI 20</li>
</ul>
</div></article></div><div id="disqus_thread"></div></div><script>var disqus_shortname = 'Lucius';
var disqus_identifier = '2020/01/11/2019，我读过的论文/';
var disqus_title = '2019，我读过的论文';
var disqus_url = 'http://luciusssss.github.io/2020/01/11/2019，我读过的论文/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//Lucius.disqus.com/count.js" async></script></main><footer class="footer-container"><div class="paginator"><a href="/2020/01/11/hello-world/" class="next">NEXT</a></div><div class="copyright"><p>© 2020 <a href="http://luciusssss.github.io">Lucius</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/AngryPowman/hexo-theme-prontera" target="_blank">hexo-theme-prontera</a>.</p></div></footer></body></html>